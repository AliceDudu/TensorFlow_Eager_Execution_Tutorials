{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eager_vs_graph.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellocybernetics/TensorFlow_Eager_Execution_Tutorials/blob/master/tutorials/00_lowlevel/eager_vs_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PmHadRahG81Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H7tDRcgs4hs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## time measurement\n",
        "In this section, we measure a calculation time.\n",
        "\n",
        "$$\n",
        "f({\\bf x}) = {\\bf W_3W_2W_1x}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "rwCqyz1rG-4G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1000),\n",
        "    tf.keras.layers.Dense(1000),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LrojM-LrHWhJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# batch_size is 1024.\n",
        "x = tf.random_normal([1024, 1000])\n",
        "y = tf.random_normal([1024, 1])\n",
        "\n",
        "def loss(y, y_pre):\n",
        "    return tf.losses.mean_squared_error(y, y_pre)\n",
        "optimizer = tf.train.GradientDescentOptimizer(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AToFnb9PHdA-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Eager Execution"
      ]
    },
    {
      "metadata": {
        "id": "5QkqMeQ0RQt3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def measurement(gpu=False):\n",
        "    if gpu:\n",
        "        device = \"/gpu:0\"\n",
        "    else:\n",
        "        device = \"/cpu:0\" \n",
        "        \n",
        "    with tf.device(device):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pre = model(x)\n",
        "            loss_value = loss(y, y_pre)\n",
        "        grads = tape.gradient(loss_value, model.variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PARxOh5_HXdM",
        "colab_type": "code",
        "outputId": "23200c1f-3084-413b-a1fc-54f411cd73c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "measurement(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 204 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CbQvbPro7klI",
        "colab_type": "code",
        "outputId": "6a5e17d0-f33e-41ce-c75d-692057dcf23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "measurement(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 25.8 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5fmjAcco8y4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## graph"
      ]
    },
    {
      "metadata": {
        "id": "_Zc8mxmd4WFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.contrib.eager.defun\n",
        "def graph_measurement(gpu=False):\n",
        "    if gpu:\n",
        "        device = \"/gpu:0\"\n",
        "    else:\n",
        "        device = \"/cpu:0\" \n",
        "        \n",
        "    with tf.device(device):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pre = model(x)\n",
        "            loss_value = loss(y, y_pre)\n",
        "        grads = tape.gradient(loss_value, model.variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjgYSvfzAR6Y",
        "colab_type": "code",
        "outputId": "3894d153-3bc8-45b1-f9ac-252be756fa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "graph_measurement(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 166 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eop4TssL8XsP",
        "colab_type": "code",
        "outputId": "8b0aedac-0a93-4cac-9043-546bc404d4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "graph_measurement(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 12.24 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 3: 16.8 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gA5kHUIu8eyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## for loop Eager"
      ]
    },
    {
      "metadata": {
        "id": "fQwCTsvL8jk_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def measurement_forloop(gpu=False):\n",
        "    if gpu:\n",
        "        device = \"/gpu:0\"\n",
        "    else:\n",
        "        device = \"/cpu:0\" \n",
        "    for _ in range(10):\n",
        "        with tf.device(device):\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pre = model(x)\n",
        "                loss_value = loss(y, y_pre)\n",
        "            grads = tape.gradient(loss_value, model.variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrw2AYYm-2zM",
        "colab_type": "code",
        "outputId": "31de44f2-0f59-48cd-f974-058ac429441b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "measurement_forloop(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 2.15 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5QEKkI_lA1w-",
        "colab_type": "code",
        "outputId": "560c6162-c1f3-4ba4-f59e-c68a9f408a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "measurement_forloop(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 260 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jwI3ETC8Hu6v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## for loop Graph"
      ]
    },
    {
      "metadata": {
        "id": "6cj1P5A2_gGI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.contrib.eager.defun\n",
        "def graph_measurement_forloop(gpu=False):\n",
        "    if gpu:\n",
        "        device = \"/gpu:0\"\n",
        "    else:\n",
        "        device = \"/cpu:0\"\n",
        "    with tf.device(device):\n",
        "        for _ in range(10):\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pre = model(x)\n",
        "                loss_value = loss(y, y_pre)\n",
        "            grads = tape.gradient(loss_value, model.variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdqkR_-d_qqn",
        "colab_type": "code",
        "outputId": "d9c13eb4-d533-4d04-e2b6-bb0ff1c2d1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "graph_measurement_forloop(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 1.7 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6CqXniJb_wVj",
        "colab_type": "code",
        "outputId": "cec8d3f5-d94b-4d3f-c996-af2e7e06d228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "graph_measurement_forloop(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 12.86 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 3: 118 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U3CXRLD5BzAl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PyTorch part"
      ]
    },
    {
      "metadata": {
        "id": "jSoSINEKH24r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "6ba0dcdd-ae2d-427b-94cb-9fbd0095a9b4"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 29kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6122a000 @  0x7f659c72a2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iXpZbyXSIH2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QTCJzBnfXNo2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(1000, 1000),\n",
        "    nn.Linear(1000, 1000),\n",
        "    nn.Linear(1000, 1),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnicGoPrXohq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn(1024, 1000)\n",
        "y = torch.randn(1024, 1)\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fg1-iSRWbUsr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## for loop Eager"
      ]
    },
    {
      "metadata": {
        "id": "YVK0lO9NX0Zf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def measurement_forloop(gpu=False):\n",
        "    if gpu:\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        device = \"cpu\" \n",
        "        \n",
        "    model.to(device)\n",
        "    \n",
        "    for _ in range(10):\n",
        "        optimizer.zero_grad() \n",
        "        y_pre = model(x.to(device))\n",
        "        loss_value = loss(y_pre, y.to(device))\n",
        "        loss_value.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VyoaNHoRaWJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7693e8a-79dc-4d58-d0b1-a49ea65714b6"
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "measurement_forloop(False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 1.53 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sf0z7NBPaaud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e619db1-68ae-4e8c-a563-440f2ab97790"
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "measurement_forloop(True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 72.2 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U5XFUwpvagcH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### for loop script (graph)"
      ]
    },
    {
      "metadata": {
        "id": "EeK1rv3NbsJB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(torch.jit.ScriptModule):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(1000, 1000),\n",
        "            nn.Linear(1000, 1000),\n",
        "            nn.Linear(1000, 1),\n",
        "        ).to('cuda')\n",
        "\n",
        "    @torch.jit.script_method\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bW7LAZofcbge",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = x.to('cuda')\n",
        "y = y.to('cuda')\n",
        "def measurement_forloop_script():\n",
        "    for _ in range(10):\n",
        "        optimizer.zero_grad() \n",
        "        y_pre = model(x)\n",
        "        loss_value = loss(y_pre, y)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UWR2MVHCe0Xh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f71e4506-eaa1-4d0a-f2e4-7b5ac3aaec0c"
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "measurement_forloop_script()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 68.8 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iYLIvmWTe4k2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}