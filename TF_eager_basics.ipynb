{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_eager_basics",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellocybernetics/TensorFlow_Eager_Execution_Tutorials/blob/master/TF_eager_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7Ps6A2NfW4cP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# To start eager execution (this must be top of code)\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dihJR-BDjW3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create Tensors"
      ]
    },
    {
      "metadata": {
        "id": "a0fFhIF28qZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fbd2f5bb-4743-4085-f0dc-7990d64660c9"
      },
      "cell_type": "code",
      "source": [
        "x = tf.convert_to_tensor(1.)\n",
        "w = tf.convert_to_tensor(2.)\n",
        "b = tf.convert_to_tensor(3.)\n",
        "\n",
        "print(type(x))\n",
        "print(x)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mgpWIN4QDquZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a computational graph for Automatic differentiation.\n",
        "When you focus the $x$ of two functions, \n",
        "\n",
        "$$\n",
        "y(x) = w  x + b\n",
        "$$ \n",
        "and\n",
        "$$ \n",
        "z(x) = w  x^2 + b x\n",
        "$$\n",
        "you can write the code of \"build a computational graph for automatic differentiation\" as below."
      ]
    },
    {
      "metadata": {
        "id": "32aRX9ZW9Ne3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dbf429e3-3f69-492c-b62c-8b04d363e688"
      },
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as g:\n",
        "    g.watch(x)\n",
        "    y = w * x + b\n",
        "    z = w * x**2 + b * x\n",
        "\n",
        "# dy/dx = 2\n",
        "# dz/dx = 4 * x + 3  (now x=1 so dz/dx = 7)\n",
        "dy_dx = g.gradient(y, x)\n",
        "dz_dx = g.gradient(z, x)\n",
        "    \n",
        "print(dy_dx)\n",
        "print(dz_dx)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n",
            "tf.Tensor(7.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xKw6MgH2ITVj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### linear model\n",
        "Linear model is as below.\n",
        "$$\n",
        " y_i = Wx_i + b\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "EtLcSHQgFULq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "455e4ad8-1f5c-4eea-a316-ee6b17d1db24"
      },
      "cell_type": "code",
      "source": [
        "x = tf.random_normal(shape=[10, 3])\n",
        "y = tf.random_normal(shape=[10, 2])\n",
        "\n",
        "# tf.keras.layers.Dense needs only output dimension.\n",
        "# When tf.keras.layers get input to calculate output at the first time,\n",
        "# the input dimension is determined.\n",
        "linear = tf.keras.layers.Dense(units=2)\n",
        "predict_y = linear(x)\n",
        "\n",
        "print(\"weight: \\n\", linear.weights[0])\n",
        "print(\"bias:\\n\", linear.weights[1], end=\"\\n\\n\")\n",
        "print(\"output shape:\\n\", y.shape)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight: \n",
            " <tf.Variable 'dense_16/kernel:0' shape=(3, 2) dtype=float32, numpy=\n",
            "array([[ 0.8318362 , -0.61764836],\n",
            "       [ 0.06596565, -0.2781443 ],\n",
            "       [-0.324251  ,  0.02151608]], dtype=float32)>\n",
            "bias:\n",
            " <tf.Variable 'dense_16/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n",
            "\n",
            "output shape:\n",
            " (10, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ga7dNc0MIc_N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### loss function\n",
        "TensorFlow eager execution has similar API to PyTorch, however the implementation of \"Build a computational graph for Automatic differentiation\"  is a little diferrent.\n",
        "At PyTorch, Tensor itself holds calculation graph, and have the method for automatic differentiation. On the other hand, at TensorFlow eager execution, computational graph is keeped by some functions (for example, `tf.GradientTape()`). \n",
        "\n",
        "When training neural network, we can use `tf.contrib.eager.implicit_value_and_gradients()`. This function recognizes the trainable parameters of NN, holds related computational graph, and return the loss value, parameter instances, and that grads."
      ]
    },
    {
      "metadata": {
        "id": "x4tHSe-DHd8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "a0ab3d89-f646-4532-962d-0b4361715753"
      },
      "cell_type": "code",
      "source": [
        "def loss_fn(model, x, y):\n",
        "    predict_y = model(x)\n",
        "    return tf.keras.losses.mean_squared_error(predict_y, y)\n",
        "\n",
        "value_and_grads = tf.contrib.eager.implicit_value_and_gradients(loss_fn)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "\n",
        "\n",
        "loss, grads = value_and_grads(model=linear, x=x, y=y)\n",
        "\n",
        "print(\"loss: \\n\", loss, end=\"\\n\\n\")\n",
        "print(\"weight grads: \\n\", grads[0][0], end=\"\\n\\n\")\n",
        "print(\"weight instances: \\n\", grads[0][1], end=\"\\n\\n\")\n",
        "print(\"bias grads: \\n\", grads[1][0], end=\"\\n\\n\")\n",
        "print(\"bias instances: \\n\", grads[1][1], end=\"\\n\\n\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: \n",
            " tf.Tensor(\n",
            "[0.04972696 1.6548975  0.33088797 0.23095478 0.6001038  1.9319891\n",
            " 2.4406717  0.98343223 0.9945836  0.40538147], shape=(10,), dtype=float32)\n",
            "\n",
            "weight grads: \n",
            " tf.Tensor(\n",
            "[[ 2.0563087 -3.6274142]\n",
            " [ 4.147823  -0.8882311]\n",
            " [-1.2567902  2.3985233]], shape=(3, 2), dtype=float32)\n",
            "\n",
            "weight instances: \n",
            " <tf.Variable 'dense_16/kernel:0' shape=(3, 2) dtype=float32, numpy=\n",
            "array([[ 0.8318362 , -0.61764836],\n",
            "       [ 0.06596565, -0.2781443 ],\n",
            "       [-0.324251  ,  0.02151608]], dtype=float32)>\n",
            "\n",
            "bias grads: \n",
            " tf.Tensor([-4.62727    1.6120654], shape=(2,), dtype=float32)\n",
            "\n",
            "bias instances: \n",
            " <tf.Variable 'dense_16/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dtX0s9fFN8Pi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Optimizing\n",
        "We aim to decrese loss value with update parameters as below. \n",
        "$$\n",
        "\\begin{align}\n",
        "W & \\leftarrow W - \\epsilon \\frac{dLoss(W)}{dW}\\\\\\\n",
        "b & \\leftarrow b - \\epsilon \\frac{dLoss(W)}{db}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where $\\epsilon$ is learning rate.\n",
        "\n",
        "After understanding this code, you are able to write training loop code."
      ]
    },
    {
      "metadata": {
        "id": "u0b2W_z4Ndw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "732a24c7-6a78-49aa-e1fc-b51cf8028acf"
      },
      "cell_type": "code",
      "source": [
        "# initial loss value of sum of all data.\n",
        "loss, grad = value_and_grads(model=linear, x=x, y=y)\n",
        "print(\"loss: \", tf.reduce_sum(loss))\n",
        "\n",
        "# update prameters using grads\n",
        "optimizer.apply_gradients(grads)\n",
        "\n",
        "# loss value after update (may be less than before update)\n",
        "loss, grad = value_and_grads(model=linear, x=x, y=y)\n",
        "print(\"loss: \", tf.reduce_sum(loss))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  tf.Tensor(9.622629, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(9.004152, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H-LY5x9o6gO2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "#### Convert to tf.Tensor from numpy.ndarray"
      ]
    },
    {
      "metadata": {
        "id": "U_sEm-NbSEU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "cf263a9d-fa98-44d6-87dc-4bc2f0d7ee3c"
      },
      "cell_type": "code",
      "source": [
        "X_numpy = np.random.randn(3, 3)\n",
        "print(type(X_numpy))\n",
        "print(X_numpy)\n",
        "\n",
        "X_tensor = tf.convert_to_tensor(X_numpy)\n",
        "print(type(X_tensor))\n",
        "print(X_tensor)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[-0.58254555  0.31973299 -1.05691421]\n",
            " [-0.50315322  0.52309492 -0.38714436]\n",
            " [-0.20711872  0.55952568  0.17786334]]\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[-0.58254555  0.31973299 -1.05691421]\n",
            " [-0.50315322  0.52309492 -0.38714436]\n",
            " [-0.20711872  0.55952568  0.17786334]], shape=(3, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x9wD2JR1TIIC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### conver to numpy.array from tf.Tensor"
      ]
    },
    {
      "metadata": {
        "id": "KFpSvjf0TRvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "b804e443-233c-4df5-ff55-2f440113789f"
      },
      "cell_type": "code",
      "source": [
        "X_tensor = tf.random_normal(shape=[3, 3])\n",
        "print(type(X_tensor))\n",
        "print(X_tensor)\n",
        "\n",
        "X_numpy = X_tensor.numpy()\n",
        "print(type(X_numpy))\n",
        "print(X_numpy)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[-0.91925687 -0.6136823  -1.4136612 ]\n",
            " [-0.5081144  -1.202485    1.4589684 ]\n",
            " [ 0.24295777 -0.2634425  -0.9960576 ]], shape=(3, 3), dtype=float32)\n",
            "<class 'numpy.ndarray'>\n",
            "[[-0.91925687 -0.6136823  -1.4136612 ]\n",
            " [-0.5081144  -1.202485    1.4589684 ]\n",
            " [ 0.24295777 -0.2634425  -0.9960576 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wKuM5lTRTYD3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### tf.Dataset pipline"
      ]
    },
    {
      "metadata": {
        "id": "sTrzI8uZUUeL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}